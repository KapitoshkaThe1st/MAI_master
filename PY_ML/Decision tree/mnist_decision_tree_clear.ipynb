{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from dt import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(f'{X.shape=}')\n",
    "\n",
    "X[0,:].reshape([8,8])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 4, sharey=True, figsize=(16,6))\n",
    "for i in range(4):\n",
    "    axes[i].imshow(X[i,:].reshape([8,8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем самодельное решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt = DecisionTree(max_tree_depth=12, min_node_records=3)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем результат обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dt.predict(x_train)\n",
    "y_test_pred = dt.predict(x_test)\n",
    "accuracy_score(y_train_pred, y_train), accuracy_score(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем решающее дерево из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=3, max_depth=12, random_state=177)\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем результат обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_pred = tree.predict(x_train)\n",
    "tree_test_pred = tree.predict(x_test)\n",
    "accuracy_score(tree_train_pred, y_train), accuracy_score(tree_test_pred , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что результаты сопоставимы, и как будто, у самодельного при прочих равных совсем чуть-чуть лучше точность на тестовой выборке, но это, скорее всего случайность, и при правильно подобраных параметрах (с помощью поиска по сетке) для обоих классификаторов реализация из sklearn должна, конечно, превзойти. \n",
    "- Кроме того, обучение самодельного решающего дерева происходит на несколько порядков дольше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше реализовал кросс-валидацию и поиск лучших гиперпараметров по сетке с помощью кросс валидации, но отладить пока не успел :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация поиска по сетке с оценкой качетсва при помощи кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator_factory, X, y, cv=5, n_repeats=3):\n",
    "    kf = RepeatedKFold(n_splits=cv, n_repeats=n_repeats, random_state=None) \n",
    "\n",
    "    metrics = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_trn, X_tst = X[train_index], X[test_index] \n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "\n",
    "        estimator = estimator_factory()\n",
    "        estimator.fit(X_trn, y_trn)\n",
    "\n",
    "        y_prd = estimator.predict(X_tst)\n",
    "\n",
    "        accuracy = accuracy_score(y_prd, y_tst)\n",
    "        metrics.append(accuracy)\n",
    "\n",
    "    return np.array(metrics)\n",
    "\n",
    "def grid_search(X, y, max_tree_depths, min_node_records):\n",
    "    best_accuracy = 0.0\n",
    "    best_max_tree_depth = None\n",
    "    best_min_node_records = None\n",
    "\n",
    "    for mtd in max_tree_depths:\n",
    "        for mnr in min_node_records:\n",
    "            print(f'trying {mtd=}, {mnr=}')\n",
    "            accuracy = np.mean(cross_validation(lambda: DecisionTree(max_tree_depth=mtd, min_node_records=mnr), X, y, cv=5, n_repeats=1))\n",
    "            print(f'accuracy: {accuracy}')\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_max_tree_depth = mtd\n",
    "                best_min_node_records = mnr\n",
    "\n",
    "    return {'best_params' : (best_max_tree_depth, best_min_node_records), 'best_score' : best_accuracy }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим кросс-валидацию на уже обученных моделях с параметрами, взятыми от балды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_validation(lambda: DecisionTree(max_tree_depth=12, min_node_records=3), x_train, y_train, cv=5, n_repeats=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(tree, x_train, y_train, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры при помощи поиска по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tree_depths = [1, 3, 5, 7, 9, 11]\n",
    "min_node_records = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "grid_search(x_train, y_train, max_tree_depths, min_node_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {'min_samples_leaf': [1, 3, 5, 7, 9], 'max_depth': [1, 3, 5, 7, 9]}\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "tree_grid.fit(x_train, y_train)\n",
    "tree_grid.best_params_, tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что результат подбора гиперпараметров для самодельного решающего дерева и реализации из sklearn совпадают, хотя, как и ожидалось, точность самодельного на оптимальных гиперпараметрах несколько меньше. Это лишний раз говорит о том, что самодельный алгоритм работает примерно так же, как реализация в sklearn, значит грубых ошибок не допущено."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и классификация (при лучших гиперпараметрах)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модели при оптимальных параметрах и проверим работу на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt = DecisionTree(max_tree_depth=9, min_node_records=1)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = dt.predict(x_train)\n",
    "y_test_pred = dt.predict(x_test)\n",
    "accuracy_score(y_train_pred, y_train), accuracy_score(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, max_depth=9)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_train_pred = tree.predict(x_train)\n",
    "tree_test_pred = tree.predict(x_test)\n",
    "accuracy_score(tree_train_pred, y_train), accuracy_score(tree_test_pred , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что для обоих моделей достигается приблизительно та же точность, что и во время подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Решающее дерево -- довольно простой алгоритм, который, однако, может довольно неплохо решать такие, довольно сложные, задачи, как распознавание рукописных символов, показывая при этом приемлемое качество классификации."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9a8acb4f733d3596df9f6fac9daff15e014d11794ebc65488d1c191c94698fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
